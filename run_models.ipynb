{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import attr\n",
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_subject_experiment_data(excel_paths=['../data_social_anxiety/social_anxiety_sagol/questionnaires_byTasks_new.xlsx'], \n",
    "                                      nifty_tasks=[('../data_social_anxiety/social_anxiety_sagol/Hariri_2ndLev/FacesVsShapes', 'hariri')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubjectExperimentData(subject_id=114, features_data={'ID': 9942, 'Age': 25, 'Gender': 1, 'GenderBIN': 0, 'Education': 14.0, 'Status': 5, 'Remarks': None, 'ExpDate': Timestamp('2018-03-02 00:00:00'), 'ScreeningDate': Timestamp('2018-02-27 00:00:00'), 'DatesDiff(days)': 3, 'Screening_LSAS': 54, 'Screening_LSAS_anx': 33, 'Screening_LSAS_avo': 21, 'RSE': 36, 'BFNE': 66, 'FPES': 29, 'STAI_T': 38, 'BDI': 10, 'RRQ_rumination': 43, 'RRQ_reflection': 19, 'RRQ': 62, 'STAXI': 20, 'Suicidality': 0, 'DPSOS_other': 24, 'DPSOS_self': 15, 'LSAS': 35, 'LSAS_anx': 24, 'LSAS_avo': 11, 'STAXI-TangT': 4, 'STAXI-TangR': 10, 'STAXI_A\\\\O': 16, 'STAXI_A\\\\I': 25, 'STAXI_C\\\\O': 29, 'STAXI_C\\\\I': 23, 'SPSRQ_reward': 13, 'SPSRQ_punishment': 9, 'NEO_O': 19, 'NEO_C': 39, 'NEO_E': 28, 'NEO_A': 30, 'NEO_N': 13, 'ISEL_12': 29, 'ISEL_appraisal support': 11, 'ISEL_belonging support': 8, 'ISEL_tangible support': 10, 'SPIN': 32, 'Music': None, 'hps_attrib': 62.5, 'lps_attrib': 25.0, 'has_attrib': 93.33, 'las_attrib': 0.0}, tasks_data={'hariri': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.subjects_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_rois() -> List[str]:\n",
    "    return \n",
    "\n",
    "def get_mask_from_roi(roi_name) -> np.array:\n",
    "    return\n",
    "\n",
    "def apply_roi_masks(experiment_data: ExperimentData, rois) -> ExperimentData:\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_MODELS = ['svr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attrs\n",
    "class Models:\n",
    "    ylabels: List[str] = attrib()\n",
    "    rois: Optional[List[str]] = attrib()\n",
    "    # (x, y, z)\n",
    "    shape: tuple = attrib() \n",
    "    # {'svr' : <model>, 'cnn': <model>}\n",
    "    models: dict = attrib()\n",
    "    \n",
    "    def save():\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @classmethod\n",
    "    def load(ylabels, rois, shape):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_models(experiment_data: List[SubjectExperimentData], ylabels, rois) -> Models:\n",
    "    if rois:\n",
    "        experiment_data = apply_roi_masks(experiment_data, rois)\n",
    "    \n",
    "    pre_computed_models = get_pre_computed_models(ylabels, rois, shape)\n",
    "    return pre_computed_models or generate_models(experiment_data, ylabels, rois)\n",
    "\n",
    "def get_pre_computed_models(ylabels, rois) -> Optional[Models]:\n",
    "    \"\"\"\n",
    "    Load serialized models for the given ylabel and rois if such models exist.\n",
    "    \"\"\"\n",
    "    \n",
    "def generate_models(experiment_data_roi_masked: List[SubjectExperimentData], ylabels, rois) -> Models:\n",
    "    models = {}\n",
    "    for model_name in AVAILABLE_MODELS:\n",
    "        models[model_name] = train_model(experiment_data_roi_masked, model_name=model_name)\n",
    "    \n",
    "    models = Models(ylabels=ylabels, rois=rois, shape=experiment_data_roi_masked.shape, models=model)\n",
    "    models.save()\n",
    "    return models\n",
    "        \n",
    "        \n",
    "def train_model(experiment_data: ExperimentData, model_name: str):\n",
    "    if model_name == 'svr':\n",
    "        train_svr(experiment_data)\n",
    "    else:\n",
    "        raise NotImplementedError(f'Model: {model_name} is not supported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.subjects_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = data[0].tasks_data['hariri'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hariri_data = [\n",
    "    {\n",
    "        'data': subject_data.tasks_data['hariri'].reshape(x*y*z),\n",
    "        'y': subject_data.features_data['FPES']\n",
    "    } for subject_data in data if 'hariri' in subject_data.tasks_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([subject['data'] for subject in hariri_data])\n",
    "y = np.array([subject['y'] for subject in hariri_data])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 558025)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = SVR(kernel='linear')\n",
    "mdl = mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999507058306588"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.14301669, 29.17136153, 31.95671716, 29.39009307, 16.21286879,\n",
       "       32.6408583 , 30.60190169, 18.09279499, 27.1604125 , 31.27011165,\n",
       "        5.89881909, 16.34961145, 32.75062112, 22.1085396 , 31.14534505,\n",
       "       29.2603911 , 29.2521457 , 30.55377023, 29.17452058])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 21, 42, 37,  0, 50, 44, 23, 35, 25, 23,  4, 48, 27, 17, 54,  1,\n",
       "       40, 29])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here I try to implement the spaceNet thing on our 4 samples.\n",
    "# it is not working since it is not enough samples\n",
    "# thats the code they used: https://nilearn.github.io/modules/generated/nilearn.decoding.SpaceNetRegressor.html#nilearn.decoding.SpaceNetRegressor\n",
    "\n",
    "\n",
    "n_subjects = 4  # increase this number if you have more RAM on your box\n",
    "imgs_paths = ['sub-120con_0001.nii', 'sub-121con_0001.nii', 'sub-122con_0001.nii', 'sub-123con_0001.nii']\n",
    "\n",
    "# Split data into training set and test set\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = Y\n",
    "rng = check_random_state(42)\n",
    "gm_imgs_train, gm_imgs_test, age_train, age_test = train_test_split(\n",
    "    imgs_paths, labels, train_size=.75, random_state=rng)\n",
    "\n",
    "print(gm_imgs_train)\n",
    "print(gm_imgs_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import SpaceNetRegressor\n",
    "\n",
    "# To save time (because these are anat images with many voxels), we include\n",
    "# only the 5-percent voxels most correlated with the age variable to fit.\n",
    "# Also, we set memory_level=2 so that more of the intermediate computations\n",
    "# are cached. Also, you may pass and n_jobs=<some_high_value> to the\n",
    "# SpaceNetRegressor class, to take advantage of a multi-core system.\n",
    "#\n",
    "# Also, here we use a graph-net penalty but more beautiful results can be\n",
    "# obtained using the TV-l1 penalty, at the expense of longer runtimes.\n",
    "decoder = SpaceNetRegressor(memory=\"nilearn_cache\", penalty=\"graph-net\",\n",
    "                            screening_percentile=5., memory_level=2)\n",
    "decoder.fit(gm_imgs_train, age_train)  # fit\n",
    "coef_img = decoder.coef_img_\n",
    "y_pred = decoder.predict(gm_imgs_test).ravel()  # predict\n",
    "mse = np.mean(np.abs(age_test - y_pred))\n",
    "print('Mean square error (MSE) on the predicted age: %.2f' % mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "brain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
